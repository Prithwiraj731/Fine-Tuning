import os
import shutil
import torch
from unsloth import FastLanguageModel
from datasets import load_dataset, concatenate_datasets
from trl import SFTConfig, SFTTrainer
from google.colab import drive

# --- Configuration ---
print("--> Configuring project parameters...")
MODEL_NAME = "microsoft/phi-2"
MAX_SEQ_LENGTH = 1024
MAX_STEPS = 500
HF_ADAPTER_DIR = "fine_tuned_phi2_medical_adapter"
MERGED_DIR = "merged_phi2_medical_model_fp16"
GGUF_OUTPUT_FILE = "phi2_medical_Q4_K_M.gguf"
DRIVE_DEST_DIR = "/content/drive/MyDrive/Medical_Phi2"

# --- Load Model & Tokenizer ---
print(f"\n--> Loading base model '{MODEL_NAME}'...")
use_bf16 = torch.cuda.is_bf16_supported()
dtype = torch.bfloat16 if use_bf16 else torch.float16

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name=MODEL_NAME, max_seq_length=MAX_SEQ_LENGTH, dtype=dtype,
    load_in_4bit=True, use_gradient_checkpointing=True, token=None, trust_remote_code=True,
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
    print("   - Set tokenizer pad_token to eos_token.")

# --- Apply LoRA Adapters ---
print("\n--> Applying LoRA adapters to the model...")
model = FastLanguageModel.get_peft_model(
    model, r=16, lora_alpha=32, lora_dropout=0.05, bias="none"
)

# --- Load & Prepare Datasets ---
print("\n--> Loading and preparing the 3 medical datasets...")
# We add `trust_remote_code=True` to the problematic dataset as required by the library.
ds1 = load_dataset("UCSD26/medical_dialog", "processed.en", split="train", trust_remote_code=True)
ds2 = load_dataset("FunDialogues/healthcare-minor-consultation", split="train")
ds3 = load_dataset("omi-health/medical-dialogue-to-soap-summary", split="train")
dataset = concatenate_datasets([ds1, ds2, ds3]).shuffle(seed=42)

possible_text_cols = ['dialogue', 'content', 'transcript', 'utterance', 'text']
text_col = next((col for col in possible_text_cols if col in dataset.column_names), None)
if not text_col:
    raise ValueError(f"Could not find a text column in the dataset. Columns found: {dataset.column_names}")
print(f"   - Using '{text_col}' as the primary text column.")

def format_chat(example):
    text = example[text_col]
    return {"text": f"<start_of_turn>user\nProvide a detailed medical summary for the following dialogue:\n\n{text}<end_of_turn>\n<start_of_turn>model\n"}

dataset = dataset.map(format_chat, remove_columns=dataset.column_names)
print("   - Dataset formatting complete.")

# --- Configure and Start Training ---
print("\n--> Configuring the trainer and starting fine-tuning...")
sft_config = SFTConfig(
    output_dir="training_output", per_device_train_batch_size=2, gradient_accumulation_steps=8,
    max_steps=MAX_STEPS, learning_rate=2e-4, logging_steps=20, save_strategy="no",
    report_to="none", dataset_text_field="text", packing=True, fp16=not use_bf16, bf16=use_bf16,
)

trainer = SFTTrainer(
    model=model, args=sft_config, train_dataset=dataset, tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH
)

trainer.train()
print("✅ Fine-tuning complete.")

# --- Save, Merge, and Convert to GGUF ---
print(f"\n--> Saving artifacts, merging, and converting to GGUF...")
print(f"   - Saving LoRA adapter to '{HF_ADAPTER_DIR}'...")
model.save_pretrained(HF_ADAPTER_DIR)
tokenizer.save_pretrained(HF_ADAPTER_DIR)

print(f"   - Merging adapter into a new model at '{MERGED_DIR}'...")
try:
    model.save_pretrained_merged(MERGED_DIR, tokenizer, save_method="merged_16bit")
    print("   - ✅ Merge successful.")
except Exception as e:
    print(f"   - ❌ ERROR: Could not merge the model. Error: {e}")
    exit()

if os.path.exists(MERGED_DIR):
    print(f"   - Converting merged model to GGUF: '{GGUF_OUTPUT_FILE}'...")
    try:
        FastLanguageModel.export_pretrained_gguf(MERGED_DIR, outfile=GGUF_OUTPUT_FILE, quant="q4_k_m")
        print("   - ✅ GGUF export successful.")
    except Exception as e:
        print(f"   - ❌ ERROR: GGUF export failed. Error: {e}")
else:
    print(f"   - ⚠️ WARN: Merged model directory not found. Skipping GGUF conversion.")

# --- Mount Drive & Copy All Artifacts ---
print("\n--> Saving all final files to Google Drive...")
try:
    drive.mount('/content/drive', force_remount=True)
    os.makedirs(DRIVE_DEST_DIR, exist_ok=True)
    print(f"   - Created/found destination folder: {DRIVE_DEST_DIR}")

    artifacts_to_copy = [HF_ADAPTER_DIR, MERGED_DIR, GGUF_OUTPUT_FILE]
    for item_path in artifacts_to_copy:
        if os.path.exists(item_path):
            dest_path = os.path.join(DRIVE_DEST_DIR, os.path.basename(item_path))
            print(f"   - Copying '{item_path}' to Drive...")
            if os.path.isdir(item_path):
                if os.path.exists(dest_path): shutil.rmtree(dest_path)
                shutil.copytree(item_path, dest_path)
            else:
                shutil.copy2(item_path, dest_path)
        else:
            print(f"   - ⚠️ WARN: Artifact not found, cannot copy: {item_path}")
    
    print("\n✅ SUCCESS! All artifacts have been copied to your Google Drive.")

except Exception as e:
    print(f"❌ ERROR: Failed to mount or copy to Google Drive. Error: {e}")

print("\n=== ALL STEPS FINISHED ===")
